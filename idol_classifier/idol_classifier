{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2be4eb68-8238-4c06-9c27-fcb2c6947f29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T07:00:39.470700Z",
     "iopub.status.busy": "2025-07-07T07:00:39.470097Z",
     "iopub.status.idle": "2025-07-07T07:00:44.272277Z",
     "shell.execute_reply": "2025-07-07T07:00:44.271442Z",
     "shell.execute_reply.started": "2025-07-07T07:00:39.470668Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- データ読み込み開始 ---\n",
      "--- データ読み込み完了 ---\n",
      "--- データシャッフル中 ---\n",
      "--- データ分割中 ---\n",
      "--- データ正規化中 ---\n",
      "--- ラベルOne-Hotエンコーディング中 ---\n",
      "--- モデル構築中 ---\n",
      "--- モデルコンパイル中 ---\n",
      "--- モデルトレーニング開始 ---\n",
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.4706 - loss: 0.6932 - val_accuracy: 0.4000 - val_loss: 0.8298\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.5294 - loss: 0.6547 - val_accuracy: 0.6000 - val_loss: 0.7155\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.4706 - loss: 0.6271 - val_accuracy: 0.4000 - val_loss: 0.6824\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 1.0000 - loss: 0.4930 - val_accuracy: 0.6000 - val_loss: 0.7660\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.8235 - loss: 0.4394 - val_accuracy: 0.6000 - val_loss: 0.7702\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.8824 - loss: 0.3725 - val_accuracy: 0.6000 - val_loss: 0.6594\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 1.0000 - loss: 0.2842 - val_accuracy: 0.6000 - val_loss: 0.6400\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 1.0000 - loss: 0.2466 - val_accuracy: 0.6000 - val_loss: 0.6204\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 1.0000 - loss: 0.1742 - val_accuracy: 0.6000 - val_loss: 0.7116\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 1.0000 - loss: 0.1422 - val_accuracy: 0.8000 - val_loss: 0.6504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- モデルトレーニング完了 ---\n",
      "\n",
      "モデルが 'idol_classifier_model.h5' として保存されました。\n",
      "\n",
      "--- モデルテスト開始 ---\n",
      "判別する画像: /home/sagemaker-user/idol_classifier/test_images/new_idol_photo.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "AIの予測結果: このアイドルは 'INI' です！ (確信度: 85.34%)\n",
      "--- モデルテスト完了 ---\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# --- 設定 ---\n",
    "IMG_SIZE = 64 # 画像をリサイズするサイズ (縦横同じ)\n",
    "\n",
    "# AIが画像を分類するカテゴリ（フォルダ名と一致させる）\n",
    "classes = ['JO1', 'INI'] \n",
    "\n",
    "# --- データ準備と前処理 ---\n",
    "data = []    # 画像データを格納するリスト\n",
    "labels = []  # 各画像がどのカテゴリに属するかを示すラベルを格納するリスト\n",
    "\n",
    "print(\"--- データ読み込み開始 ---\")\n",
    "for c in classes:\n",
    "    # 現在のディレクトリにある 'JO1' または 'INI' フォルダへのパスを作成\n",
    "    # os.getcwd() は現在コードが実行されているディレクトリを指します\n",
    "    path = os.path.join(os.getcwd(), c) # 'c' は 'JO1' または 'INI'\n",
    "    \n",
    "    # フォルダが存在するかチェック\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"エラー: フォルダ '{path}' が見つかりません。'{c}' フォルダが現在のディレクトリに存在するか確認してください。\")\n",
    "        continue # このカテゴリの処理をスキップ\n",
    "\n",
    "    # フォルダ内のすべてのファイル名をリストアップ\n",
    "    for img_filename in os.listdir(path):\n",
    "        # 画像ファイルのフルパスを作成\n",
    "        img_path = os.path.join(path, img_filename)\n",
    "        \n",
    "        # 画像ファイル以外（例えば.DS_Storeなど）をスキップ\n",
    "        if not os.path.isfile(img_path):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # 画像を読み込み (OpenCVを使用)、指定したサイズにリサイズ\n",
    "            image = cv2.imread(img_path)\n",
    "            # 画像が正しく読み込まれたか確認\n",
    "            if image is None:\n",
    "                print(f\"警告: 画像ファイル '{img_path}' を読み込めませんでした。スキップします。\")\n",
    "                continue\n",
    "            \n",
    "            image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "            \n",
    "            # 画像データと対応するラベルをリストに追加\n",
    "            data.append(image)\n",
    "            labels.append(classes.index(c)) # 'JO1'なら0、'INI'なら1\n",
    "            \n",
    "            # 読み込んだ画像のパスを表示 (進行状況の確認用)\n",
    "            # print(f\"読み込み中: {img_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            # 画像読み込みやリサイズ中にエラーが発生した場合\n",
    "            print(f\"エラー発生: {img_path} - {e}\")\n",
    "\n",
    "print(\"--- データ読み込み完了 ---\")\n",
    "\n",
    "# 読み込んだデータが存在するか確認\n",
    "if not data:\n",
    "    print(\"エラー: 読み込む画像ファイルが見つかりませんでした。フォルダに画像が正しく配置されているか確認してください。\")\n",
    "    print(f\"期待されるフォルダ: {os.path.join(os.getcwd(), classes[0])}, {os.path.join(os.getcwd(), classes[1])}\")\n",
    "    exit() # データがないので処理を終了\n",
    "\n",
    "data = np.array(data)    # リストをNumPy配列に変換\n",
    "labels = np.array(labels) # リストをNumPy配列に変換\n",
    "\n",
    "# --- データシャッフル ---\n",
    "print(\"--- データシャッフル中 ---\")\n",
    "idx = np.arange(data.shape[0]) # データのインデックスを生成\n",
    "np.random.shuffle(idx)        # インデックスをシャッフル\n",
    "data = data[idx]              # シャッフルされたインデックスに基づいてデータを並べ替え\n",
    "labels = labels[idx]          # シャッフルされたインデックスに基づいてラベルを並べ替え\n",
    "\n",
    "# --- データ分割 (トレーニング用と検証用) ---\n",
    "print(\"--- データ分割中 ---\")\n",
    "num_samples = len(data)\n",
    "# 全体の80%をトレーニング用データに、20%を検証用データにする\n",
    "num_train = int(num_samples * 0.8) \n",
    "x_train = data[:num_train]\n",
    "y_train = labels[:num_train]\n",
    "x_val = data[num_train:]\n",
    "y_val = labels[num_train:]\n",
    "\n",
    "# --- 画像データの正規化 ---\n",
    "# 画像のピクセル値は通常0〜255なので、AIが扱いやすいように0〜1の範囲に変換する\n",
    "print(\"--- データ正規化中 ---\")\n",
    "x_train = x_train / 255.0\n",
    "x_val = x_val / 255.0\n",
    "\n",
    "# --- ラベルのOne-Hotエンコーディング ---\n",
    "# AIの最終出力形式に合わせるため、ラベルを変換 (例: 'JO1' -> [1, 0], 'INI' -> [0, 1])\n",
    "print(\"--- ラベルOne-Hotエンコーディング中 ---\")\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "\n",
    "# --- モデルの構築 (AIの「脳」を作る部分) ---\n",
    "print(\"--- モデル構築中 ---\")\n",
    "model = Sequential() # 順番に層を積み重ねていくモデル\n",
    "\n",
    "# 最初の畳み込み層とプーリング層\n",
    "model.add(Conv2D(32, (3, 3), input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# 2番目の畳み込み層とプーリング層\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# 全結合層\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 出力層 (2つのカテゴリに分類するため、出力ニューロンは2つ)\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# --- モデルのコンパイル ---\n",
    "print(\"--- モデルコンパイル中 ---\")\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# --- モデルのトレーニング（学習） ---\n",
    "print(\"--- モデルトレーニング開始 ---\")\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=10,\n",
    "          batch_size=32,\n",
    "          validation_data=(x_val, y_val))\n",
    "\n",
    "print(\"--- モデルトレーニング完了 ---\")\n",
    "\n",
    "# --- 学習済みモデルを保存する ---\n",
    "model.save('idol_classifier_model.h5')\n",
    "print(\"\\nモデルが 'idol_classifier_model.h5' として保存されました。\")\n",
    "\n",
    "# --- モデルを使った予測の例 ---\n",
    "# ... (モデルのトレーニング完了までのコードは省略) ...\n",
    "\n",
    "# --- モデルを使った予測の例 ---\n",
    "print(\"\\n--- モデルテスト開始 ---\")\n",
    "\n",
    "\n",
    "test_image_path = os.path.join(os.getcwd(), 'test_images', 'new_idol_photo.jpg') # <--- ここをあなたの画像パスに書き換える！\n",
    "\n",
    "try:\n",
    "    print(f\"判別する画像: {test_image_path}\")\n",
    "\n",
    "    # 画像を読み込み、リサイズ、正規化\n",
    "    image_selected = cv2.imread(test_image_path)\n",
    "    if image_selected is None:\n",
    "        print(f\"エラー: 画像ファイル '{test_image_path}' を読み込めませんでした。パスまたはファイルを確認してください。\")\n",
    "    else:\n",
    "        image_selected = cv2.resize(image_selected, (IMG_SIZE, IMG_SIZE))\n",
    "        image_selected = np.expand_dims(image_selected, axis=0) # AIモデルの入力形式に合わせる (バッチ次元を追加)\n",
    "        image_selected = image_selected / 255.0 # 正規化 (0-1の範囲に)\n",
    "\n",
    "        # 予測を実行\n",
    "        prediction = model.predict(image_selected)\n",
    "        # print(f\"予測結果の生データ: {prediction}\") # 確率の配列 (例: [[0.1, 0.9]])\n",
    "\n",
    "        # 予測結果の解釈\n",
    "        predicted_class_index = np.argmax(prediction) # 最も確率が高いクラスのインデックス (0か1)\n",
    "        predicted_class_name = classes[predicted_class_index] # そのインデックスに対応するクラス名 ('jpop'か'kpop')\n",
    "        confidence = prediction[0][predicted_class_index] * 100 # そのクラスである確信度（パーセンテージ）\n",
    "\n",
    "        print(f\"AIの予測結果: このアイドルは '{predicted_class_name}' です！ (確信度: {confidence:.2f}%)\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"エラー: 指定された画像ファイル '{test_image_path}' が見つかりませんでした。\")\n",
    "except Exception as e:\n",
    "    print(f\"予測中に予期せぬエラーが発生しました: {e}\")\n",
    "\n",
    "print(\"--- モデルテスト完了 ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82fb69a-554d-4e38-ab4f-17d31dca32ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
