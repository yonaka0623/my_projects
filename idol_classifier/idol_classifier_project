{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7656839f-f9d0-4ecd-becd-9879cdccfb46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-09T14:23:14.866938Z",
     "iopub.status.busy": "2025-07-09T14:23:14.866386Z",
     "iopub.status.idle": "2025-07-09T14:23:27.015472Z",
     "shell.execute_reply": "2025-07-09T14:23:27.012319Z",
     "shell.execute_reply.started": "2025-07-09T14:23:14.866744Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 14:23:15.742404: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- データ読み込み開始 ---\n",
      "--- データ読み込み完了 ---\n",
      "--- データシャッフル中 ---\n",
      "--- データ分割中 ---\n",
      "--- データ正規化中 ---\n",
      "--- ラベルOne-Hotエンコーディング中 ---\n",
      "--- モデル構築中 ---\n",
      "--- モデルコンパイル中 ---\n",
      "--- モデルトレーニング開始 ---\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.3750 - loss: 0.6988 - val_accuracy: 0.4000 - val_loss: 1.2434\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.5625 - loss: 0.7719 - val_accuracy: 0.6000 - val_loss: 0.6846\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.9375 - loss: 0.6197 - val_accuracy: 0.6000 - val_loss: 0.6248\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.5000 - loss: 0.6368 - val_accuracy: 0.6000 - val_loss: 0.6653\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 0.9375 - loss: 0.5379 - val_accuracy: 0.4000 - val_loss: 0.7650\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - accuracy: 0.9375 - loss: 0.4756 - val_accuracy: 0.4000 - val_loss: 0.8511\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.8125 - loss: 0.4357 - val_accuracy: 0.4000 - val_loss: 0.8239\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.8750 - loss: 0.3755 - val_accuracy: 0.4000 - val_loss: 0.6934\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.9375 - loss: 0.3105 - val_accuracy: 0.8000 - val_loss: 0.5888\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 1.0000 - loss: 0.2663 - val_accuracy: 0.8000 - val_loss: 0.5747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- モデルトレーニング完了 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "モデルが 'idol_classifier_model.h5' として保存されました。\n",
      "\n",
      "--- モデルテスト開始 ---\n",
      "モデル 'idol_classifier_model.h5' をロードしました。\n",
      "判別する画像: /home/sagemaker-user/my_projects/idol_classifier/test_images/new_idol_photo.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
      "AIの予測結果: このアイドルは 'JO1' です！ (確信度: 57.73%)\n",
      "--- モデルテスト完了 ---\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# AIアイドル分類AI (JO1 vs INI) コード\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2 # 画像処理ライブラリ\n",
    "# TensorFlow 2.x 以降のKeras APIをインポート\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation\n",
    "from tensorflow.keras.utils import to_categorical # ラベル変換用\n",
    "\n",
    "# --- 設定 ---\n",
    "IMG_SIZE = 64 # 画像をリサイズするサイズ (縦横同じ)\n",
    "\n",
    "# AIが画像を分類するカテゴリ（フォルダ名と完全に一致させる）\n",
    "# 'JO1' フォルダの画像を0番目のカテゴリ、'INI' フォルダの画像を1番目のカテゴリとして学習します。\n",
    "classes = ['JO1', 'INI']\n",
    "\n",
    "# --- データ準備と前処理 ---\n",
    "data = []    # 画像データを格納するリスト\n",
    "labels = []  # 各画像がどのカテゴリに属するかを示すラベルを格納するリスト\n",
    "\n",
    "print(\"--- データ読み込み開始 ---\")\n",
    "current_working_directory = os.getcwd() # 現在の実行ディレクトリを取得\n",
    "\n",
    "for c in classes:\n",
    "    # 現在のディレクトリにある 'JO1' または 'INI' フォルダへのパスを作成\n",
    "    # 例: /path/to/your/idol_classifier_project/JO1\n",
    "    path = os.path.join(current_working_directory, c)\n",
    "    \n",
    "    # フォルダが存在するかチェック\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"エラー: フォルダ '{path}' が見つかりません。'{c}' フォルダが '{current_working_directory}' 内に存在するか確認してください。\")\n",
    "        continue # このカテゴリの処理をスキップ\n",
    "\n",
    "    # フォルダ内のすべてのファイル名をリストアップ\n",
    "    for img_filename in os.listdir(path):\n",
    "        # 画像ファイルのフルパスを作成\n",
    "        img_path = os.path.join(path, img_filename)\n",
    "        \n",
    "        # 画像ファイル以外（例えば隠しファイルなど）をスキップ\n",
    "        if not os.path.isfile(img_path):\n",
    "            # print(f\"スキップ: '{img_path}' はファイルではありません。\") # デバッグ用\n",
    "            continue\n",
    "        \n",
    "        # 画像ファイルの拡張子を確認して画像のみを処理\n",
    "        # (一般的な画像拡張子をリストアップ)\n",
    "        valid_extensions = ('.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff', '.webp')\n",
    "        if not img_filename.lower().endswith(valid_extensions):\n",
    "            # print(f\"スキップ: '{img_filename}' は画像ファイルではありません。\") # デバッグ用\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # 画像を読み込み (OpenCVを使用)、指定したサイズにリサイズ\n",
    "            image = cv2.imread(img_path)\n",
    "            \n",
    "            # 画像が正しく読み込まれたか確認 (読み込み失敗するとNoneになる)\n",
    "            if image is None:\n",
    "                print(f\"警告: 画像ファイル '{img_path}' を読み込めませんでした。破損している可能性があります。スキップします。\")\n",
    "                continue\n",
    "            \n",
    "            image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "            \n",
    "            # 画像データと対応するラベルをリストに追加\n",
    "            data.append(image)\n",
    "            labels.append(classes.index(c)) # 'JO1'なら0、'INI'なら1\n",
    "            \n",
    "            # 読み込んだ画像のパスを表示 (進行状況の確認用。量が多いと出力が長くなるのでコメントアウト推奨)\n",
    "            # print(f\"読み込み中: {img_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            # 画像読み込みやリサイズ中に予期せぬエラーが発生した場合\n",
    "            print(f\"エラー発生: {img_path} - {e}\")\n",
    "\n",
    "print(\"--- データ読み込み完了 ---\")\n",
    "\n",
    "# 読み込んだデータが存在するか最終確認\n",
    "if not data:\n",
    "    print(\"\\n致命的なエラー: 読み込む画像ファイルが全く見つかりませんでした。\")\n",
    "    print(f\"以下のフォルダ内に画像が正しく配置されているか、ファイル名が正しいか確認してください。\")\n",
    "    for cls_name in classes:\n",
    "        print(f\"- {os.path.join(current_working_directory, cls_name)}\")\n",
    "    exit() # データがないので、これ以上は処理を終了\n",
    "\n",
    "data = np.array(data)    # リストをNumPy配列に変換\n",
    "labels = np.array(labels) # リストをNumPy配列に変換\n",
    "\n",
    "# --- データシャッフル ---\n",
    "print(\"--- データシャッフル中 ---\")\n",
    "idx = np.arange(data.shape[0]) # データのインデックスを生成\n",
    "np.random.shuffle(idx)        # インデックスをシャッフル\n",
    "data = data[idx]              # シャッフルされたインデックスに基づいてデータを並べ替え\n",
    "labels = labels[idx]          # シャッフルされたインデックスに基づいてラベルを並べ替え\n",
    "\n",
    "# --- データ分割 (トレーニング用と検証用) ---\n",
    "print(\"--- データ分割中 ---\")\n",
    "num_samples = len(data)\n",
    "# 全体の80%をトレーニング用データに、20%を検証用データにする\n",
    "num_train = int(num_samples * 0.8) \n",
    "\n",
    "# 最低限のデータチェック (トレーニングデータが空になるのを防ぐ)\n",
    "if num_train == 0:\n",
    "    print(\"\\n警告: トレーニングデータが1枚もありません。総画像数が少なすぎる可能性があります。\")\n",
    "    print(\"少なくとも2枚以上の画像が必要です。トレーニングデータ数: 0\")\n",
    "    # 代わりに、すべてのデータをトレーニングデータとして扱う (検証なし)\n",
    "    x_train = data\n",
    "    y_train = labels\n",
    "    x_val = np.array([]) # 検証データは空にする\n",
    "    y_val = np.array([])\n",
    "else:\n",
    "    x_train = data[:num_train]\n",
    "    y_train = labels[:num_train]\n",
    "    x_val = data[num_train:]\n",
    "    y_val = labels[num_train:]\n",
    "\n",
    "\n",
    "# --- 画像データの正規化 ---\n",
    "# 画像のピクセル値は通常0〜255なので、AIが扱いやすいように0〜1の範囲に変換する\n",
    "print(\"--- データ正規化中 ---\")\n",
    "x_train = x_train / 255.0\n",
    "# 検証データが存在する場合のみ正規化\n",
    "if x_val.size > 0:\n",
    "    x_val = x_val / 255.0\n",
    "\n",
    "# --- ラベルのOne-Hotエンコーディング ---\n",
    "# AIの最終出力形式に合わせるため、ラベルを変換 (例: 'JO1' -> [1, 0], 'INI' -> [0, 1])\n",
    "print(\"--- ラベルOne-Hotエンコーディング中 ---\")\n",
    "y_train = to_categorical(y_train, num_classes=len(classes)) # num_classesを指定するとより安全\n",
    "# 検証データが存在する場合のみエンコーディング\n",
    "if y_val.size > 0:\n",
    "    y_val = to_categorical(y_val, num_classes=len(classes))\n",
    "\n",
    "# --- モデルの構築 (AIの「脳」を作る部分) ---\n",
    "print(\"--- モデル構築中 ---\")\n",
    "model = Sequential() # 順番に層を積み重ねていくモデル\n",
    "\n",
    "# 最初の畳み込み層とプーリング層\n",
    "# Conv2D: 画像の特徴を抽出する層 (32個のフィルター)\n",
    "# Activation('relu'): 活性化関数（ニューラルネットワークの非線形性を導入）\n",
    "# MaxPooling2D: 特徴マップを圧縮する層 (画像のサイズを小さくする)\n",
    "model.add(Conv2D(32, (3, 3), input_shape=x_train.shape[1:])) # 入力画像の形 (縦, 横, チャンネル数)\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# 2番目の畳み込み層とプーリング層\n",
    "model.add(Conv2D(64, (3, 3))) # 64個のフィルター\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# 全結合層\n",
    "# Flatten: 畳み込み層からの2次元の出力を1次元に変換\n",
    "# Dense: 全ての入力と接続される層\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64)) # 64個のニューロン\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 出力層 (2つのカテゴリに分類するため、出力ニューロンは2つ)\n",
    "# Dense(len(classes)): 分類したいカテゴリの数と一致させる\n",
    "# Activation('softmax'): 各カテゴリに属する確率を出力する活性化関数（合計が1になる）\n",
    "model.add(Dense(len(classes))) # classesリストの数に自動で合わせる\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# --- モデルのコンパイル ---\n",
    "# モデルがどのように学習するかを設定する部分\n",
    "print(\"--- モデルコンパイル中 ---\")\n",
    "model.compile(loss='categorical_crossentropy', # 損失関数: 分類問題でよく使われる\n",
    "              optimizer='adam',             # 最適化関数: 学習を効率的に進めるアルゴリズム\n",
    "              metrics=['accuracy'])         # 評価指標: 学習の精度を見る\n",
    "\n",
    "# --- モデルのトレーニング（学習） ---\n",
    "# AIに実際に画像を「勉強」させる部分\n",
    "print(\"--- モデルトレーニング開始 ---\")\n",
    "# 検証データがない場合はvalidation_dataを除外\n",
    "if x_val.size > 0:\n",
    "    history = model.fit(x_train, y_train,        # トレーニングデータとラベル\n",
    "                        epochs=10,             # 学習を繰り返す回数\n",
    "                        batch_size=32,         # 一度にAIに与える画像の枚数\n",
    "                        validation_data=(x_val, y_val)) # 検証用データ\n",
    "else:\n",
    "    print(\"警告: 検証データがないため、トレーニングデータのみで学習します。\")\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        epochs=10,\n",
    "                        batch_size=32)\n",
    "\n",
    "print(\"--- モデルトレーニング完了 ---\")\n",
    "\n",
    "# --- 学習済みモデルを保存する ---\n",
    "# 次回から学習済みのAIをすぐに使えるように、ファイルとして保存しておく\n",
    "model_save_path = 'idol_classifier_model.h5'\n",
    "model.save(model_save_path)\n",
    "print(f\"\\nモデルが '{model_save_path}' として保存されました。\")\n",
    "\n",
    "# --- モデルを使った予測の例 ---\n",
    "# 学習したAIが正しく分類できるかテストする部分\n",
    "print(\"\\n--- モデルテスト開始 ---\")\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "try:\n",
    "    # 保存したモデルをロード\n",
    "    loaded_model = load_model(model_save_path)\n",
    "    print(f\"モデル '{model_save_path}' をロードしました。\")\n",
    "\n",
    "    # ★★★ ここを修正します！★★★\n",
    "    # あなたが判別させたい画像のパスをここに直接記述してください。\n",
    "    # test_images フォルダの中の 'new_idol_photo.jpg' をテストします。\n",
    "    test_image_filename = 'new_idol_photo.jpg' # test_imagesフォルダの中のファイル名\n",
    "    test_image_path = os.path.join(os.getcwd(), 'test_images', test_image_filename)\n",
    "\n",
    "    print(f\"判別する画像: {test_image_path}\")\n",
    "\n",
    "    # 画像を読み込み、リサイズ、正規化\n",
    "    image_to_predict = cv2.imread(test_image_path)\n",
    "    if image_to_predict is None:\n",
    "        print(f\"エラー: 画像ファイル '{test_image_path}' を読み込めませんでした。パスまたはファイルを確認してください。\")\n",
    "        raise FileNotFoundError # 読み込めない場合は例外を発生させる\n",
    "    \n",
    "    image_to_predict = cv2.resize(image_to_predict, (IMG_SIZE, IMG_SIZE))\n",
    "    image_to_predict = np.expand_dims(image_to_predict, axis=0) # AIモデルの入力形式に合わせる (バッチ次元を追加)\n",
    "    image_to_predict = image_to_predict / 255.0 # 正規化 (0-1の範囲に)\n",
    "\n",
    "    # 予測を実行\n",
    "    prediction = loaded_model.predict(image_to_predict)\n",
    "    # print(f\"予測結果の生データ: {prediction}\") # 確率の配列 (例: [[0.1, 0.9]])\n",
    "\n",
    "    # 予測結果の解釈\n",
    "    predicted_class_index = np.argmax(prediction) # 最も確率が高いクラスのインデックス (0か1)\n",
    "    predicted_class_name = classes[predicted_class_index] # そのインデックスに対応するクラス名 ('JO1'か'INI')\n",
    "    confidence = prediction[0][predicted_class_index] * 100 # そのクラスである確信度（パーセンテージ）\n",
    "\n",
    "    print(f\"AIの予測結果: このアイドルは '{predicted_class_name}' です！ (確信度: {confidence:.2f}%)\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"エラー: 指定された画像ファイル '{test_image_path}' が見つかりませんでした。\")\n",
    "except Exception as e:\n",
    "    print(f\"モデルテスト中に予期せぬエラーが発生しました: {e}\")\n",
    "\n",
    "print(\"--- モデルテスト完了 ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
